name: ReMaster

services:
  mongo:
    image: mongo:8.0.13
    container_name: remaster-mongo
    ports:
      - 27017:27017
    volumes:
      - mongo_data:/data/db
    networks:
      - remaster-network
    healthcheck:
      test: [CMD, mongosh, --eval, db.adminCommand('ping')]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:8.2.1-alpine
    container_name: remaster-redis
    ports:
      - 6379:6379
    volumes:
      - redis_data:/data
    networks:
      - remaster-network
    healthcheck:
      test: [CMD, redis-cli, ping]
      interval: 10s
      timeout: 5s
      retries: 5
    command: redis-server --appendonly yes

  api-gateway:
    build:
      context: ../..
      dockerfile: services/api-gateway/Dockerfile
    container_name: remaster-api-gateway
    depends_on:
      auth-service:
        condition: service_healthy
    ports:
      - 8080:8080
    env_file:
      - ../../.env
    volumes:
      - ../../services/api-gateway:/app/services/api-gateway
      - ../../shared:/app/shared
    logging:
      driver: local
    networks:
      - remaster-network
    restart: unless-stopped

  auth-service:
    build:
      context: ../..
      dockerfile: services/auth/Dockerfile
    container_name: remaster-auth-service
    depends_on:
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - 9091:9091 # gRPC
    env_file:
      - ../../.env
    volumes:
      - ../../services/auth-service:/app/services/auth-service
      - ../../shared:/app/shared
    logging:
      driver: local
    networks:
      - remaster-network
    restart: unless-stopped
    healthcheck:
      test:
        [
          CMD,
          sh,
          -c,
          netstat -an | grep :9091 | grep LISTEN || ss -an | grep :9091 | grep LISTEN,
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

networks:
  remaster-network:
    driver: bridge

volumes:
  mongo_data:
    driver: local
  redis_data:
    driver: local

  # zookeeper:
  #   image: confluentinc/cp-zookeeper:7.4.0
  #   container_name: remaster-zookeeper
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   networks:
  #     - remaster-network

  # kafka:
  #   image: confluentinc/cp-kafka:7.4.0
  #   container_name: remaster-kafka
  #   depends_on:
  #     - zookeeper
  #   ports:
  #     - 9092:9092
  #   environment:
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  #   networks:
  #     - remaster-network
  #   healthcheck:
  #     test: [CMD, kafka-broker-api-versions, --bootstrap-server, localhost:9092]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 5

  # kafka-ui:
  #   image: provectuslabs/kafka-ui:latest
  #   container_name: remaster-kafka-ui
  #   depends_on:
  #     - kafka
  #   ports:
  #     - 8090:8080
  #   environment:
  #     KAFKA_CLUSTERS_0_NAME: local
  #     KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
  #   networks:
  #     - remaster-network

  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: remaster-prometheus
  #   ports:
  #     - 9090:9090
  #   volumes:
  #     - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
  #     - prometheus_data:/prometheus
  #   command:
  #     - --config.file=/etc/prometheus/prometheus.yml
  #     - --storage.tsdb.path=/prometheus
  #     - --web.console.libraries=/etc/prometheus/console_libraries
  #     - --web.console.templates=/etc/prometheus/consoles
  #     - --web.enable-lifecycle
  #     - --web.enable-admin-api
  #   networks:
  #     - remaster-network

  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: remaster-grafana
  #   ports:
  #     - 3000:3000
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #     - ./infrastructure/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
  #     - ./infrastructure/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
  #   networks:
  #     - remaster-network
  #   depends_on:
  #     - prometheus

  # # MinIO for AWS S3 emulation
  # minio:
  #   image: minio/minio:latest
  #   container_name: remaster-minio
  #   ports:
  #     - 9000:9000
  #     - 9001:9001
  #   environment:
  #     MINIO_ROOT_USER: minioadmin
  #     MINIO_ROOT_PASSWORD: minioadmin
  #   volumes:
  #     - minio_data:/data
  #   command: server /data --console-address :9001
  #   networks:
  #     - remaster-network
  #   healthcheck:
  #     test: [CMD, curl, -f, http://localhost:9000/minio/health/live]
  #     interval: 30s
  #     timeout: 20s
  #     retries: 3

  # # Jaeger for tracing
  # jaeger:
  #   image: jaegertracing/all-in-one:latest
  #   container_name: remaster-jaeger
  #   ports:
  #     - 16686:16686
  #     - 14268:14268
  #   environment:
  #     COLLECTOR_OTLP_ENABLED: true
  #   networks:
  #     - remaster-network

  # prometheus_data:
  #   driver: local
  # grafana_data:
  #   driver: local
  # minio_data:
  #   driver: local
